# rparams - params grid
# gparams - params grid for gridsearch
# "metrics": [['accuracy'],['average_precision'],['f1'],['f1_micro'],['f1_macro'],['f1_weighted'],['f1_samples'],['neg_log_loss'],['precision'],['recall'],['roc_auc']]


[DEFAULT]
epochs = 30
ep = 30

[mperceptron]
rparams = {
    "batch_size": 8
    }

gparams = {
    "epochs" : [%(ep)s, 10, 20, 50, 100],
    "batch_size": [8, 32, 64, 128, 256, 512],
    "activation_1": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_2": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, .0001, .00001],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "class_weight": ['balanced', None],
    "neurons_1":[10,20,30,50,100,200,500,1000,2000],
    "neurons_2":[10,20,30,50,100,200,500,1000,2000],
    "layers":[1,2,3,4,5,10]
    }


[perceptron]
rparams = {
    "batch_size": 32, 
    "activation": 'sigmoid',    
    "optimizer": 'Nadam', 
    "loss": 'mean_squared_error',    
    "learning_rate": 0.001,    
    "momentum": 0.2,
    "init_mode": 'glorot_normal',
    "metrics": ['accuracy']
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 2048],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, .0001, .00001],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "metrics": [['accuracy']]
    }

[residual]
rparams = {
    "batch_size": 8, 
    "activation_0": 'relu', 
    "activation_1": 'relu', 
    "activation_2": 'relu', 
    "optimizer": 'Adam', 
    "loss": 'binary_crossentropy',    
    # "neurons": 32, 
    "learning_rate": .001, 
    "momentum": .1,
    "init_mode": 'uniform',
    "metrics": ['accuracy'],
    "dropout": 0.1,
    "layers": 3
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 1024],
    "activation_0": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_1": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_2": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 
            'mean_squared_logarithmic_error', 'squared_hinge', 'hinge','binary_crossentropy','kullback_leibler_divergence','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, 0.0001, .00001],
    "momentum": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "layers": [1,2,3,5,10],
    "metrics": [['accuracy']]
    }

[xgb]
rparams = {
    'learning_rate': 0.1, 
    'n_estimators': 1000, 
    'seed':0, 
    'subsample': 0.8, 
    'colsample_bytree': 0.8,
    'objective': 'binary:logistic'
    }
    
gparams = {
    'n_estimators': [100, 200, 500, 700, 1000],
    "learning_rate": [2/100, 3/100, 4/100, 5/100, 6/100, 7/100, 8/100, 9/100, 10/100], 
    'subsample': [0.1, 0.3, 0.5, 0.75, 0.8, 1.0], 
    'colsample_bytree': [0.1, 0.4, 0.6, 0.8, 1.0], 
    'max_depth': [4, 6, 8, 10],
    'min_split_gain' : [0],
    'min_child_weight': [3/5, 3/10, 3/15]
    }

[svc]
rparams = {'C':1.0, 'cache_size':200, 'coef0':0.0,
    'decision_function_shape':'ovr', 'degree':3, 'gamma':'auto', 'kernel':'rbf',
    'max_iter':-1}
    
gparams = {
    'C':[1.0, 10.0, 100.0, 1000.0, 20000, 40000, 100000, 3, 5],
    'kernel':['poly', 'rbf', 'sigmoid'],
    'degree': [3,5,7,9,13,15],
    'gamma': [0.1, 0.2, 0.5, 0.7, .3, .6, .9, 1],
    'shrinking' : [True, False],
    'class_weight': ['balanced', None]
    }

[knn]
rparams = {'n_neighbors':2, 'weights':'uniform', 'algorithm':'auto', 'leaf_size':30, 'p':2, 'metric':'minkowski'}
    
gparams = {
    'n_neighbors':[2, 3, 5, 7, 9, 13, 15, 17],
    'weights': ['uniform', 'distance'],
    'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],
    'leaf_size': [1,3,5,9,10, 20, 30, 50, 100,5000],
    'p' : [2, 3, 5, 7, 9, 13],
    'metric':['minkowski', 'euclidean', "manhattan"]
    }

[logreg]
targets = [0]

rparams = {'C':1.0}

    
gparams = {
    'C': [1, 10.0, 30, 50.0, 60, 65, 70, 85, 80.0, 75, 100, 105, 95, 200.0, 300, 500, 900, 950, 1000.0, 1050, 1100, 1500, 2000.0, 5000, 10000, 100000, 1000000, 5000000],
    'max_iter': [10, 100, 150, 200, 30, 40, 50, 60, 3000, 5000, 10000, 15000, 30000, 5000000, 2000000, 1000000, 20000000, 50000000, 100000000, 200000000, 500000000, 1000000000],
    'solver': ['saga', 'sag', 'newton-cg', 'lbfgs', 'liblinear'],
    'class_weight':['balanced', None]
    }


[rf]
rparams = {
    'n_jobs' : -1, 
    'verbose' : 2
    }
    
gparams = {
    'n_estimators' : [10, 20, 100, 200, 300, 500, 2000, 5000, 15000],
    'min_samples_leaf' : [1, 5, 10, 15, 30, 60, 100, 200, 3, 500, 1000],
    'min_samples_split' : [2, 3, 5, 10, 15, 30, 60, 100, 500],
    'min_weight_fraction_leaf' : [0.1, .2, .3, .4, .5],
    'max_leaf_nodes' : [2, 3, 5, 10, 15, 30, 60, 100, 500],
    'criterion' : ['gini', 'entropy'],
    "class_weight": ['balanced', None]
    }

[if]
rparams = {
    'n_jobs' : -1, 
    'verbose' : 2
    }
    
gparams = {
    'verbose' : [2],
    'n_estimators' : [10, 100, 500, 1000, 5000],
    'contamination' : [0.1, 0.2, 0.3, 0.4, 0.5],
    'bootstrap' : ['True', 'False']
    }


[lstm]
rparams = {
    "batch_size": 32
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [8, 16, 32],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "neurons" : [8,16,32,64,256, 512,1024],
    "embedding_length" : [8,16,32,64,256]
    }
    
[rnn]
rparams = {
    "batch_size": 32
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [8, 16, 32],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "neurons" : [8,16,32,64,256, 512,1024],
    "embedding_length" : [8,16,32,64,256]
    }
    
[gru]
rparams = {
    "batch_size": 32
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [8, 16, 32],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "neurons" : [8,16,32,64,256, 512,1024],
    "embedding_length" : [8,16,32,64,256]
    }

[mlstm]
rparams = {
    "batch_size": 32
    }

gparams = {
    "batch_size": [64],
    "epochs" : [%(ep)s, 10, 30, 50],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "layers": [0,1,2,3,4,5],
    "neurons_1" : [8,16,32,64,256],
    "neurons_2" : [8,16,32,64,256]
    }
